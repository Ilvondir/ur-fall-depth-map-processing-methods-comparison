{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8785065c",
   "metadata": {},
   "source": [
    "# Basic depth map processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b86abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed=4242):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9724cceb",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b09c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'adl' # fall, adl\n",
    "sequence_number = random.randint(0, 40 if label == 'adl' else 30) + 1\n",
    "selected_video = Path(f'../datasets/{label}/sequence-{sequence_number:02}')\n",
    "\n",
    "frames = sorted(selected_video.glob('*.png'))\n",
    "\n",
    "for frame_path in frames:\n",
    "\n",
    "    gray = cv2.imread(str(frame_path), cv2.IMREAD_GRAYSCALE)\n",
    "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    viridis = cv2.applyColorMap(gray, cv2.COLORMAP_VIRIDIS)\n",
    "    viridis = cv2.cvtColor(viridis, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(viridis)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'{label.capitalize()} sequence #{sequence_number}')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbbcbf",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ccb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.sequences = []\n",
    "        self.transform = transform\n",
    "        self.number_of_frames = 256\n",
    "\n",
    "        classes = ['adl', 'fall']\n",
    "        for label_idx, cls in enumerate(classes):\n",
    "            cls_path = Path(root_dir) / cls\n",
    "            for seq_folder in cls_path.iterdir():\n",
    "                if seq_folder.is_dir():\n",
    "                    frames = sorted(seq_folder.glob(\"*.png\"))\n",
    "                    imgs = []\n",
    "                    for f in frames:\n",
    "                        gray = cv2.imread(str(f), cv2.IMREAD_GRAYSCALE)\n",
    "                        gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "                        viridis = cv2.applyColorMap(gray, cv2.COLORMAP_VIRIDIS)\n",
    "                        viridis = cv2.cvtColor(viridis, cv2.COLOR_BGR2RGB)\n",
    "                        img = Image.fromarray(viridis)\n",
    "                        if self.transform:\n",
    "                            img = self.transform(img)\n",
    "                        imgs.append(img)\n",
    "                    self.sequences.append((imgs, label_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        imgs, label = self.sequences[idx] \n",
    "        T = len(imgs)\n",
    "\n",
    "        if T >= self.number_of_frames:\n",
    "            imgs = imgs[-self.number_of_frames:]\n",
    "        else:\n",
    "            pad = self.number_of_frames - T\n",
    "            first = imgs[0]\n",
    "            imgs = [first for _ in range(pad)] + imgs\n",
    "\n",
    "        video_tensor = torch.stack(imgs)  # (T, C, H, W)\n",
    "        return video_tensor, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4772cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "root_dir = Path('../datasets')\n",
    "\n",
    "dataset = VideoDataset(root_dir, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a1239",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25093bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, cnn_model='resnet18', hidden_size=256, num_classes=2, pretrained=True):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        \n",
    "        self.cnn = models.resnet18(pretrained=pretrained)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])  # output: (B, 512, 1, 1)\n",
    "\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.feature_dim = 512\n",
    "        self.lstm = nn.LSTM(input_size=self.feature_dim, hidden_size=hidden_size, \n",
    "                          num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, T, C, H, W)\n",
    "        B = batch_size\n",
    "        T = num_frames\n",
    "        C = channels\n",
    "        H = height\n",
    "        W = width\n",
    "        \"\"\"\n",
    "        B, T, C, H, W = x.size()\n",
    "\n",
    "        cnn_features = []\n",
    "        for t in range(T):\n",
    "            frame = x[:, t, :, :, :]        # (B, C, H, W)\n",
    "            feat = self.cnn(frame)          # (B, 512, 1, 1)\n",
    "            feat = feat.view(B, -1)         # (B, 512)\n",
    "            cnn_features.append(feat)\n",
    "        \n",
    "\n",
    "        cnn_features = torch.stack(cnn_features, dim=1)\n",
    "\n",
    "        lstm_out, _ = self.lstm(cnn_features) \n",
    "\n",
    "        last_time_step = lstm_out[:, -1, :] # (B, hidden_size)\n",
    "        out = self.fc(last_time_step) # (B, num_classes)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50766ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/ur-fall/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/ur-fall/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = CNN_LSTM().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# summary(model, input_size=(4, 256, 3, 224, 224), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b99c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] TRAIN -> Loss: 0.6318, Accuracy: 59.32%\n",
      "Epoch [1/10] VAL   -> Loss: 0.5017, Accuracy: 90.91%\n",
      "\tSaved\n",
      "Epoch [2/10] TRAIN -> Loss: 0.5179, Accuracy: 81.36%\n",
      "Epoch [2/10] VAL   -> Loss: 0.5194, Accuracy: 72.73%\n",
      "Epoch [3/10] TRAIN -> Loss: 0.3774, Accuracy: 91.53%\n",
      "Epoch [3/10] VAL   -> Loss: 0.2202, Accuracy: 100.00%\n",
      "\tSaved\n",
      "Epoch [4/10] TRAIN -> Loss: 0.2958, Accuracy: 88.14%\n",
      "Epoch [4/10] VAL   -> Loss: 0.1251, Accuracy: 100.00%\n",
      "\tSaved\n",
      "Epoch [5/10] TRAIN -> Loss: 0.2039, Accuracy: 96.61%\n",
      "Epoch [5/10] VAL   -> Loss: 0.1628, Accuracy: 100.00%\n",
      "Epoch [6/10] TRAIN -> Loss: 0.1261, Accuracy: 96.61%\n",
      "Epoch [6/10] VAL   -> Loss: 0.0881, Accuracy: 100.00%\n",
      "\tSaved\n",
      "Epoch [7/10] TRAIN -> Loss: 0.0384, Accuracy: 100.00%\n",
      "Epoch [7/10] VAL   -> Loss: 0.0693, Accuracy: 100.00%\n",
      "\tSaved\n",
      "Epoch [8/10] TRAIN -> Loss: 0.0722, Accuracy: 98.31%\n",
      "Epoch [8/10] VAL   -> Loss: 0.0388, Accuracy: 100.00%\n",
      "\tSaved\n",
      "Epoch [9/10] TRAIN -> Loss: 0.3794, Accuracy: 77.97%\n",
      "Epoch [9/10] VAL   -> Loss: 0.1803, Accuracy: 100.00%\n",
      "Epoch [10/10] TRAIN -> Loss: 0.1555, Accuracy: 98.31%\n",
      "Epoch [10/10] VAL   -> Loss: 0.0879, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "seed_everything(42)\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "labels = [dataset[i][1] for i in indices]\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.15, stratify=labels, random_state=42)\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True, generator=g)\n",
    "\n",
    "\n",
    "checkpoint_dir = Path('../models')\n",
    "checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "best_val_loss = 1e10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ===================== TRAIN =====================\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (videos, labels) in enumerate(train_loader):\n",
    "        videos = videos.to(device)   # (B, T, C, H, W)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(videos)      # (B, num_classes)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * videos.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] TRAIN -> Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    # ===================== VALIDATION =====================\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for videos, labels in val_loader:\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * videos.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] VAL   -> Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    # ===================== CHECKPOINT =====================\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint_path = checkpoint_dir / f'best_model_viridis.pt'\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"\\tSaved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "11\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(len(train_idx))\n",
    "print(len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ed7f7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1: 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7289fa1a2e40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_path = checkpoint_dir / 'best_model_viridis.pt'\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for videos, labels in DataLoader(dataset, batch_size=4, shuffle=False):\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(videos)               # (B, num_classes)\n",
    "        _, predicted = torch.max(outputs, 1)  # (B,)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "prec = precision_score(all_labels, all_preds, average='binary')\n",
    "rec = recall_score(all_labels, all_preds, average='binary')\n",
    "f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec*100:.2f}%\")\n",
    "print(f\"Recall: {rec*100:.2f}%\")\n",
    "print(f\"F1: {f1*100:.2f}%\")\n",
    "\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ur-fall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
