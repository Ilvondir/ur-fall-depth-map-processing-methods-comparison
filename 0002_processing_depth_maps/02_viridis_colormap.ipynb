{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8785065c",
   "metadata": {},
   "source": [
    "# Basic depth map processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b86abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed=4242):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9724cceb",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b09c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'adl' # fall, adl\n",
    "sequence_number = random.randint(0, 40 if label == 'adl' else 30) + 1\n",
    "selected_video = Path(f'../datasets/{label}/sequence-{sequence_number:02}')\n",
    "\n",
    "frames = sorted(selected_video.glob('*.png'))\n",
    "\n",
    "for frame_path in frames:\n",
    "\n",
    "    gray = cv2.imread(str(frame_path), cv2.IMREAD_GRAYSCALE)\n",
    "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    viridis = cv2.applyColorMap(gray, cv2.COLORMAP_VIRIDIS)\n",
    "    viridis = cv2.cvtColor(viridis, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(viridis)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'{label.capitalize()} sequence #{sequence_number}')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbbcbf",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ed177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"../datasets\")\n",
    "out_root = Path(\"../data_viridis\")\n",
    "out_root.mkdir(exist_ok=True)\n",
    "\n",
    "for cls in [\"adl\", \"fall\"]:\n",
    "    for seq in (root / cls).iterdir():\n",
    "        out_seq = out_root / cls / seq.name\n",
    "        out_seq.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for f in seq.glob(\"*.png\"):\n",
    "            gray = cv2.imread(str(f), cv2.IMREAD_GRAYSCALE)\n",
    "            gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            viridis = cv2.applyColorMap(gray, cv2.COLORMAP_VIRIDIS)\n",
    "            viridis = cv2.cvtColor(viridis, cv2.COLOR_BGR2RGB)\n",
    "            np.save(out_seq / f\"{f.stem}.npy\", viridis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ccb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None, number_of_frames=64):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        self.number_of_frames = number_of_frames\n",
    "\n",
    "        classes = ['adl', 'fall']\n",
    "        for label_idx, cls in enumerate(classes):\n",
    "            cls_path = Path(root_dir) / cls\n",
    "            for seq_folder in cls_path.iterdir():\n",
    "                frames = sorted(seq_folder.glob(\"*.npy\"))\n",
    "                if frames:\n",
    "                    self.samples.append((frames, label_idx))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_paths, label = self.samples[idx]\n",
    "\n",
    "        if len(frame_paths) >= self.number_of_frames:\n",
    "            frame_paths = frame_paths[-self.number_of_frames:]\n",
    "        else:\n",
    "            frame_paths = [frame_paths[0]] * (self.number_of_frames - len(frame_paths)) + frame_paths\n",
    "\n",
    "        imgs = []\n",
    "        for f in frame_paths:\n",
    "            arr = np.load(f).astype(np.float32)          # (H, W, 3)\n",
    "            img = Image.fromarray((arr * 255).astype(np.uint8)) # (3, H, W)\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            imgs.append(img)\n",
    "\n",
    "        video = torch.stack(imgs)  # (T, 3, H, W)\n",
    "        return video, label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4772cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "root_dir = Path(out_root)\n",
    "\n",
    "dataset = VideoDataset(root_dir, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a1239",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25093bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=256, num_classes=2, pretrained=True):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        \n",
    "        self.cnn = models.resnet18(pretrained=pretrained)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])  # output: (B, 512, 1, 1)\n",
    "\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.feature_dim = 512\n",
    "        self.lstm = nn.LSTM(input_size=self.feature_dim, hidden_size=hidden_size, \n",
    "                          num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, T, C, H, W)\n",
    "        B = batch_size\n",
    "        T = num_frames\n",
    "        C = channels\n",
    "        H = height\n",
    "        W = width\n",
    "        \"\"\"\n",
    "        B, T, C, H, W = x.size()\n",
    "\n",
    "        cnn_features = []\n",
    "        for t in range(T):\n",
    "            frame = x[:, t, :, :, :]        # (B, C, H, W)\n",
    "            feat = self.cnn(frame)          # (B, 512, 1, 1)\n",
    "            feat = feat.view(B, -1)         # (B, 512)\n",
    "            cnn_features.append(feat)\n",
    "        \n",
    "\n",
    "        cnn_features = torch.stack(cnn_features, dim=1)\n",
    "\n",
    "        lstm_out, _ = self.lstm(cnn_features) \n",
    "\n",
    "        last_time_step = lstm_out[:, -1, :] # (B, hidden_size)\n",
    "        out = self.fc(last_time_step) # (B, num_classes)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50766ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/ur-fall/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/ur-fall/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = CNN_LSTM().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# summary(model, input_size=(4, 256, 3, 224, 224), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096242a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339ddb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "num_folds = 10\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "seed_everything(42)\n",
    "\n",
    "indices = np.arange(len(dataset))\n",
    "labels = np.array([dataset[i][1] for i in indices])\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=num_folds,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "checkpoint_dir = Path('../models/viridis_colormap')\n",
    "checkpoint_dir.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74066df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FOLD 1/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.6783 Acc: 55.56% | VAL Loss: 0.6222 Acc: 71.43%\n",
      "Epoch [2/10] TRAIN Loss: 0.5381 Acc: 85.71% | VAL Loss: 0.4870 Acc: 85.71%\n",
      "Epoch [3/10] TRAIN Loss: 0.4212 Acc: 93.65% | VAL Loss: 0.3017 Acc: 100.00%\n",
      "Epoch [4/10] TRAIN Loss: 0.2172 Acc: 98.41% | VAL Loss: 0.1327 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.1839 Acc: 95.24% | VAL Loss: 0.1023 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.0765 Acc: 98.41% | VAL Loss: 0.0287 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.1776 Acc: 88.89% | VAL Loss: 0.1436 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.1830 Acc: 93.65% | VAL Loss: 0.0588 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.1457 Acc: 95.24% | VAL Loss: 0.2713 Acc: 85.71%\n",
      "Epoch [10/10] TRAIN Loss: 0.3327 Acc: 90.48% | VAL Loss: 0.0739 Acc: 100.00%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n",
      "\n",
      "========== FOLD 2/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.5095 Acc: 71.43% | VAL Loss: 0.2619 Acc: 85.71%\n",
      "Epoch [2/10] TRAIN Loss: 0.1568 Acc: 96.83% | VAL Loss: 0.0806 Acc: 100.00%\n",
      "Epoch [3/10] TRAIN Loss: 0.2726 Acc: 90.48% | VAL Loss: 0.0498 Acc: 100.00%\n",
      "Epoch [4/10] TRAIN Loss: 0.2171 Acc: 88.89% | VAL Loss: 0.0642 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.1792 Acc: 90.48% | VAL Loss: 0.0788 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.0606 Acc: 100.00% | VAL Loss: 0.0535 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.2828 Acc: 92.06% | VAL Loss: 0.1066 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.1119 Acc: 98.41% | VAL Loss: 0.1226 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.0658 Acc: 96.83% | VAL Loss: 0.0307 Acc: 100.00%\n",
      "Epoch [10/10] TRAIN Loss: 0.2908 Acc: 92.06% | VAL Loss: 0.2720 Acc: 85.71%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n",
      "\n",
      "========== FOLD 3/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.0679 Acc: 96.83% | VAL Loss: 0.0795 Acc: 100.00%\n",
      "Epoch [2/10] TRAIN Loss: 0.2511 Acc: 92.06% | VAL Loss: 0.0284 Acc: 100.00%\n",
      "Epoch [3/10] TRAIN Loss: 0.3662 Acc: 85.71% | VAL Loss: 0.0372 Acc: 100.00%\n",
      "Epoch [4/10] TRAIN Loss: 0.1012 Acc: 96.83% | VAL Loss: 0.0602 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.0504 Acc: 100.00% | VAL Loss: 0.0260 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.2619 Acc: 90.48% | VAL Loss: 0.0879 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.0668 Acc: 100.00% | VAL Loss: 0.1324 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.2903 Acc: 85.71% | VAL Loss: 0.0460 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.0776 Acc: 98.41% | VAL Loss: 0.0450 Acc: 100.00%\n",
      "Epoch [10/10] TRAIN Loss: 0.0394 Acc: 100.00% | VAL Loss: 0.0175 Acc: 100.00%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n",
      "\n",
      "========== FOLD 4/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.0221 Acc: 100.00% | VAL Loss: 0.0260 Acc: 100.00%\n",
      "Epoch [2/10] TRAIN Loss: 0.0654 Acc: 98.41% | VAL Loss: 0.1678 Acc: 100.00%\n",
      "Epoch [3/10] TRAIN Loss: 0.0612 Acc: 100.00% | VAL Loss: 0.0405 Acc: 100.00%\n",
      "Epoch [4/10] TRAIN Loss: 0.2648 Acc: 88.89% | VAL Loss: 0.0451 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.1899 Acc: 87.30% | VAL Loss: 0.0619 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.0628 Acc: 98.41% | VAL Loss: 0.0877 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.1822 Acc: 92.06% | VAL Loss: 0.0287 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.0486 Acc: 100.00% | VAL Loss: 0.0363 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.3059 Acc: 84.13% | VAL Loss: 0.1056 Acc: 100.00%\n",
      "Epoch [10/10] TRAIN Loss: 0.0917 Acc: 100.00% | VAL Loss: 0.0915 Acc: 100.00%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n",
      "\n",
      "========== FOLD 5/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.0124 Acc: 100.00% | VAL Loss: 0.0117 Acc: 100.00%\n",
      "Epoch [2/10] TRAIN Loss: 0.0255 Acc: 100.00% | VAL Loss: 0.0137 Acc: 100.00%\n",
      "Epoch [3/10] TRAIN Loss: 0.0198 Acc: 100.00% | VAL Loss: 0.1486 Acc: 85.71%\n",
      "Epoch [4/10] TRAIN Loss: 0.0148 Acc: 100.00% | VAL Loss: 0.0103 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.0106 Acc: 100.00% | VAL Loss: 0.0081 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.0123 Acc: 100.00% | VAL Loss: 0.0242 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.1916 Acc: 93.65% | VAL Loss: 0.0190 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.1713 Acc: 92.06% | VAL Loss: 0.0248 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.2767 Acc: 85.71% | VAL Loss: 0.2306 Acc: 85.71%\n",
      "Epoch [10/10] TRAIN Loss: 0.0379 Acc: 100.00% | VAL Loss: 0.0443 Acc: 100.00%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n",
      "\n",
      "========== FOLD 6/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.4298 Acc: 82.54% | VAL Loss: 0.0572 Acc: 100.00%\n",
      "Epoch [2/10] TRAIN Loss: 0.0835 Acc: 100.00% | VAL Loss: 0.0371 Acc: 100.00%\n",
      "Epoch [3/10] TRAIN Loss: 0.1848 Acc: 90.48% | VAL Loss: 0.2977 Acc: 85.71%\n",
      "Epoch [4/10] TRAIN Loss: 0.0847 Acc: 98.41% | VAL Loss: 0.0243 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.1933 Acc: 88.89% | VAL Loss: 0.1008 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.0697 Acc: 98.41% | VAL Loss: 0.0225 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.0876 Acc: 96.83% | VAL Loss: 0.0369 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.0803 Acc: 98.41% | VAL Loss: 0.0219 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.0991 Acc: 96.83% | VAL Loss: 0.0131 Acc: 100.00%\n",
      "Epoch [10/10] TRAIN Loss: 0.1364 Acc: 95.24% | VAL Loss: 0.0426 Acc: 100.00%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n",
      "\n",
      "========== FOLD 7/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.1405 Acc: 96.83% | VAL Loss: 0.0247 Acc: 100.00%\n",
      "Epoch [2/10] TRAIN Loss: 0.0159 Acc: 100.00% | VAL Loss: 0.0517 Acc: 100.00%\n",
      "Epoch [3/10] TRAIN Loss: 0.0713 Acc: 98.41% | VAL Loss: 0.1092 Acc: 100.00%\n",
      "Epoch [4/10] TRAIN Loss: 0.1386 Acc: 95.24% | VAL Loss: 0.0282 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.1683 Acc: 88.89% | VAL Loss: 0.0985 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.0607 Acc: 96.83% | VAL Loss: 0.0169 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.0191 Acc: 100.00% | VAL Loss: 0.0688 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.2537 Acc: 85.71% | VAL Loss: 0.0929 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.2332 Acc: 87.30% | VAL Loss: 0.0875 Acc: 100.00%\n",
      "Epoch [10/10] TRAIN Loss: 0.0718 Acc: 98.41% | VAL Loss: 0.0183 Acc: 100.00%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n",
      "\n",
      "========== FOLD 8/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.0303 Acc: 100.00% | VAL Loss: 0.0141 Acc: 100.00%\n",
      "Epoch [2/10] TRAIN Loss: 0.0260 Acc: 100.00% | VAL Loss: 0.0290 Acc: 100.00%\n",
      "Epoch [3/10] TRAIN Loss: 0.1160 Acc: 95.24% | VAL Loss: 0.0525 Acc: 100.00%\n",
      "Epoch [4/10] TRAIN Loss: 0.1884 Acc: 90.48% | VAL Loss: 0.0452 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.1352 Acc: 95.24% | VAL Loss: 0.0535 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.1717 Acc: 93.65% | VAL Loss: 0.0537 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.1929 Acc: 90.48% | VAL Loss: 0.1283 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.0967 Acc: 96.83% | VAL Loss: 0.0795 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.1016 Acc: 95.24% | VAL Loss: 0.1583 Acc: 100.00%\n",
      "Epoch [10/10] TRAIN Loss: 0.1125 Acc: 95.24% | VAL Loss: 0.0389 Acc: 100.00%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n",
      "\n",
      "========== FOLD 9/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.0184 Acc: 100.00% | VAL Loss: 0.0714 Acc: 100.00%\n",
      "Epoch [2/10] TRAIN Loss: 0.0154 Acc: 100.00% | VAL Loss: 0.0100 Acc: 100.00%\n",
      "Epoch [3/10] TRAIN Loss: 0.0405 Acc: 98.41% | VAL Loss: 0.0147 Acc: 100.00%\n",
      "Epoch [4/10] TRAIN Loss: 0.1034 Acc: 96.83% | VAL Loss: 0.0067 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.0233 Acc: 100.00% | VAL Loss: 0.0120 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.3331 Acc: 92.06% | VAL Loss: 0.0502 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.0427 Acc: 100.00% | VAL Loss: 0.0619 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.0282 Acc: 100.00% | VAL Loss: 0.0302 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.0159 Acc: 100.00% | VAL Loss: 0.0145 Acc: 100.00%\n",
      "Epoch [10/10] TRAIN Loss: 0.0373 Acc: 100.00% | VAL Loss: 0.0132 Acc: 100.00%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n",
      "\n",
      "========== FOLD 10/10 ==========\n",
      "Epoch [1/10] TRAIN Loss: 0.0304 Acc: 100.00% | VAL Loss: 0.0264 Acc: 100.00%\n",
      "Epoch [2/10] TRAIN Loss: 0.0221 Acc: 100.00% | VAL Loss: 0.0196 Acc: 100.00%\n",
      "Epoch [3/10] TRAIN Loss: 0.2507 Acc: 93.65% | VAL Loss: 0.0134 Acc: 100.00%\n",
      "Epoch [4/10] TRAIN Loss: 0.0743 Acc: 96.83% | VAL Loss: 0.0300 Acc: 100.00%\n",
      "Epoch [5/10] TRAIN Loss: 0.0583 Acc: 98.41% | VAL Loss: 0.0443 Acc: 100.00%\n",
      "Epoch [6/10] TRAIN Loss: 0.0106 Acc: 100.00% | VAL Loss: 0.0173 Acc: 100.00%\n",
      "Epoch [7/10] TRAIN Loss: 0.1683 Acc: 92.06% | VAL Loss: 0.0146 Acc: 100.00%\n",
      "Epoch [8/10] TRAIN Loss: 0.1900 Acc: 92.06% | VAL Loss: 0.0381 Acc: 100.00%\n",
      "Epoch [9/10] TRAIN Loss: 0.1275 Acc: 98.41% | VAL Loss: 0.0232 Acc: 100.00%\n",
      "Epoch [10/10] TRAIN Loss: 0.1585 Acc: 95.24% | VAL Loss: 0.1130 Acc: 100.00%\n",
      "Fold results: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0}\n"
     ]
    }
   ],
   "source": [
    "fold_results = []\n",
    "\n",
    "full_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        pin_memory=True,\n",
    "        generator=g\n",
    "    )\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(indices, labels)):\n",
    "    print(f\"\\n========== FOLD {fold+1}/{num_folds} ==========\")\n",
    "\n",
    "    train_dataset = Subset(dataset, train_idx)\n",
    "    val_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        pin_memory=True,\n",
    "        generator=g\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    best_val_loss = 1e10\n",
    "    best_model_path = checkpoint_dir / f'best_model_fold_{fold}.pt'\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ===================== TRAIN =====================\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for videos, y in train_loader:\n",
    "            videos = videos.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * videos.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        train_loss /= len(train_dataset)\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # ===================== VAL =====================\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for videos, y in val_loader:\n",
    "                videos = videos.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                outputs = model(videos)\n",
    "                loss = criterion(outputs, y)\n",
    "\n",
    "                val_loss += loss.item() * videos.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        val_loss /= len(val_dataset)\n",
    "        val_acc = 100 * correct / total\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "            f\"TRAIN Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | \"\n",
    "            f\"VAL Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    # ===================== EVAL BEST MODEL =====================\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for videos, y in full_loader:\n",
    "            videos = videos.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            outputs = model(videos)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    fold_metrics = {\n",
    "        'acc': accuracy_score(all_labels, all_preds),\n",
    "        'prec': precision_score(all_labels, all_preds, average='binary'),\n",
    "        'rec': recall_score(all_labels, all_preds, average='binary'),\n",
    "        'f1': f1_score(all_labels, all_preds, average='binary'),\n",
    "    }\n",
    "\n",
    "    fold_results.append(fold_metrics)\n",
    "\n",
    "    print(\"Fold results:\", fold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "122099a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== CV RESULTS ==========\n",
      "ACC: 100.00% std: 0.00%\n",
      "PREC: 100.00% std: 0.00%\n",
      "REC: 100.00% std: 0.00%\n",
      "F1: 100.00% std: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n========== CV RESULTS ==========\")\n",
    "\n",
    "for metric in fold_results[0].keys():\n",
    "    values = [f[metric] for f in fold_results]\n",
    "    print(\n",
    "        f\"{metric.upper()}: \"\n",
    "        f\"{np.mean(values)*100:.2f}% std: {np.std(values)*100:.2f}%\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ur-fall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
